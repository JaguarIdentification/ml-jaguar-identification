{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DavidePanza/ml-jaguar-identification/blob/main/notebooks/02_dataset_creation/Gdino_SAM2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vF7PPS2JJ02I"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import os\n",
        "import sys\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "!pip install fiftyone -q\n",
        "import fiftyone as fo\n",
        "import fiftyone.zoo as foz\n",
        "from fiftyone import ViewField as F\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive\n",
        "\n",
        "from google.colab import userdata\n",
        "HF_TOKEN = userdata.get('HF_token')\n",
        "\n",
        "!pip install huggingface_hub -q\n",
        "from huggingface_hub import login\n",
        "login(token=HF_TOKEN)\n",
        "\n",
        "# import from gdino_utils\n",
        "notebook_dir = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
        "src_path = os.path.join(notebook_dir, 'src')\n",
        "sys.path.append(src_path)\n",
        "from gdino_utils import select_best_detection_head, select_best_detection_body"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Upload the Dataset\n",
        "This script loads a FiftyOne dataset from the specified directory, linking it to raw image files stored in a separate folder. It enables access to both the dataset annotations and the corresponding image files for visualization or processing."
      ],
      "metadata": {
        "id": "EdDfu2Fz5INF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load images\n",
        "image_dir = Path('path/to/your/images')\n",
        "input_dir = Path('path/to/your/fo_dataset')\n",
        "\n",
        "dataset = fo.Dataset.from_dir(\n",
        "    dataset_dir=str(input_dir),\n",
        "    dataset_type=fo.types.FiftyOneDataset,\n",
        "    rel_dir=image_dir,\n",
        ")"
      ],
      "metadata": {
        "id": "-lLm2EfK5HCJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run Grounding-Dino\n",
        "This script loads a Grounding DINO zero-shot object detection model from the FiftyOne model zoo, configured to detect either \"jaguar's whole body\" or \"Close-up of a jaguar's head\" based on the DETECTION_TYPE flag.   \n",
        "It runs the model on the dataset, saving predictions in the appropriate raw_bboxes_body or raw_bboxes_head field, using a confidence threshold of 0.2 and a text similarity threshold of 0.6.  \n",
        "It then selects the best detection depending on the chosen detection type and removes the raw bounding box field after processing."
      ],
      "metadata": {
        "id": "g7nGzneCDXuH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuration\n",
        "DETECTION_TYPE = \"body\"  # or \"head\" - set this flag to choose processing type\n",
        "\n",
        "# Load appropriate model based on detection type\n",
        "model = foz.load_zoo_model(\n",
        "    \"zero-shot-detection-transformer-torch\",\n",
        "    name_or_path=\"IDEA-Research/grounding-dino-tiny\",\n",
        "    classes=[\"jaguar's whole body\" if DETECTION_TYPE == \"body\" else \"Close-up of a jaguar's head\"]\n",
        ")\n",
        "\n",
        "# Define the name of the bboxes field\n",
        "raw_bboxes_name = f\"raw_bboxes_{DETECTION_TYPE}\"\n",
        "\n",
        "# run model\n",
        "dataset.apply_model(model,\n",
        "                    label_field=raw_bboxes_name,\n",
        "                    confidence_thresh=0.2,\n",
        "                    text_threshold=.6)\n",
        "\n",
        "if DETECTION_TYPE == \"body\":\n",
        "    # If you computed bboxes for whole body\n",
        "    select_best_detection_body(dataset, raw_bboxes_field_name=raw_bboxes_name)\n",
        "else:\n",
        "    # If you computed bboxes for head only\n",
        "    select_best_detection_head(dataset, raw_bboxes_field_name=raw_bboxes_name)\n",
        "\n",
        "# Remove raw bboxes\n",
        "dataset.delete_sample_field(raw_bboxes_name)"
      ],
      "metadata": {
        "id": "-rUakrJSQVRz",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run SAM2\n",
        "This code loads a SAM segmentation model and applies it to the dataset using bounding boxes as prompts.  \n",
        "It stores the results in either segmentations_head or segmentations_body based on the detection type."
      ],
      "metadata": {
        "id": "B_iE5mW6tJ2F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define fields based on detection type\n",
        "prompt_field = \"bboxes_head\" if DETECTION_TYPE == \"head\" else \"bboxes_body\"\n",
        "label_field = \"segmentations_head\" if DETECTION_TYPE == \"head\" else \"segmentations_body\"\n",
        "\n",
        "# Load the segmentation model\n",
        "model = foz.load_zoo_model(\"segment-anything-vitb-torch\")\n",
        "\n",
        "# Apply the model to the dataset\n",
        "dataset.apply_model(\n",
        "    model,\n",
        "    label_field=label_field,\n",
        "    prompt_field=prompt_field,\n",
        ")"
      ],
      "metadata": {
        "id": "tFJ0sV7-tNaE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Store metadata locally"
      ],
      "metadata": {
        "id": "WtR7DGLgnCtB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "storage_dir = Path('path/to/your/fo_dataset')\n",
        "os.makedirs(storage_dir, exist_ok=True)\n",
        "\n",
        "dataset.export(\n",
        "    export_dir=str(storage_dir),\n",
        "    dataset_type=fo.types.FiftyOneDataset,\n",
        "    export_media=False,\n",
        "    rel_dir=image_dir\n",
        ")"
      ],
      "metadata": {
        "id": "x7wkMnxNIRHz"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
